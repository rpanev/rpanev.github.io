---
id: 499
title: Какво представлява файлът robots.txt и как да създадем подходящ за нашия сайт?
date: 2014-03-26T19:42:10+00:00
author: panev
layout: post
guid: http://panevinfo.eu/blog//?p=499
permalink: '/%d0%ba%d0%b0%d0%ba%d0%b2%d0%be-%d0%bf%d1%80%d0%b5%d0%b4%d1%81%d1%82%d0%b0%d0%b2%d0%bb%d1%8f%d0%b2%d0%b0-%d1%84%d0%b0%d0%b9%d0%bb%d1%8a%d1%82-robots-txt-%d0%b8-%d0%ba%d0%b0%d0%ba-%d0%b4%d0%b0-%d1%81.html'
tie_views:
  - "167"
image: /wp-content/uploads/2014/03/seo.jpg
categories:
  - SEO
---
Когато търсите в интернет страници по интересуваща ви тема, най-вероятно ползвате услугите на някоя от интернет търсачките: Google, Yahoo, Excite и пр. Правило ли ви е впечатление колко бързо идват отговорите на въпросите ви? Страницата с резултатите, която получавате за секунди, обаче не е композирана на мига. Търсачките търпеливо са обикаляли милионите сайтове в интернет, събирали са информация за това кой сайт на каква тематика е (този процес се нарича индексиране на страниците: включване в списъка) и са сортирали тези данни в таблици &#8211; по ключови думи. Именно от тези таблици търсачките изваждат адресите на страниците, които най-добре съответстват на ключовите думи, по които сте задали търсенето.  
<!--more-->

  
Програмите, които извършват тази колосална работа по обикаляне на интернет сайтовете, се наричат роботи (robots) или още паяци (spiders). Всяка търсачка ползва свой робот: за Google това е Googlebot, за Yahoo: Yahoo Slurp и т.н. Ако вие искате страниците ви да се появяват като резултати от търсене в тези търсачки, трябва да им съобщите за съществуването си: подробности можете да научите от статията Класиране на сайта ви: СЕО.

Тук ще се занимаем с въпроса как да забраните на роботите да обикалят сайта ви &#8211; части от него или в цялост. Защо ще искате да ограничите достъпа на роботите щом те са толкова важни за класирането на сайта ви в резултатите от тъсене? Ето няколко причини:

Не искате роботите да индексират съдържанието на картинната ви галерия. Там може би сте сложили лични снимки, които не искате да се появяват при търсене в Google Images примерно.  
Имате папка с много големи файлове (снимките са само един пример), индексирането на които не само че не ви носи полза, но намалява месечния ви лимит за пренос на данни (bandwidth).  
На сайта сте оставили временни файлове, които скоро ще бъдат изтрити и не желаете съдържанието им да бъде достъпно дълго време след като сте ги изтрили. За пояснение търсачките често правят архивни копия на страниците, които индексират. Тези копия са достъпни за потребителите под формата на &#8222;кеширани страници&#8220; дори след като оригиналите на сайта ви са били изтрити или променени.  
Не желаете някой с едно кликване да си свали целия ви сайт на собствения си компютър. Има програми (напр. HTTPTrack), които правят точно това. Освен че ви натоварват сървъра и правят излишен трафик, програмите позволяват по този начин някой недоборсъвестен уеб дизайнер да направи за нула време огледален сайт на вашия. Щом ще краде (реално няма как да го спрете) &#8211; нека поне малко се потруди.

Какви са правилата за писане на robots.txt ?

Файлът robots.txt по същество е забранителен. Ако не напишете такъв, по подразбиране всички роботи ще могат свободно да обикалят по сайта ви. Файлът трябва да съхраните с точно това име: robots.txt и да го запишете в основната директория, където са файловете-страници на сайта ви. Тази директория обикновено е именувана като public_html или нещо подобно.Нека разгледаме един примерен robots.txt файл:

User-agent: *  
Disallow: /gallery/  
Disallow: /temporary/  
Disallow: /dokumenti/star_dokument.html

На първия ред определяте за кой/и робот(и) ще се отнасят следващите команди. Винаги се използва командата User-agent: , като след нея се изписват имената на роботите. Ако искате командите да се отнасят за всички роботи, използвайте звездичка (*).

На втория ред указвате кой файл или галерия да бъдат забранени за достъп. Използва се командата Disallow: и след нея името на папката или файла, който ще бъде забранен за достъп. Ако искате да забраните повече от една папка, трябва на отделен ред да повторите командата Disallow: и да изпишете следващия адрес на папка или файл за забрана.

В горния пример забраняваме на всички роботи да обикалят из папки gallery и temporary, както и всички папки и файлове, които евентуално се съдържт в тях. На последния ред забраняваме индексирането на файла star_dokument.html в папка /dokumenti. Ако има други файлове в тази директория, те ще бъдат свободни за индексиране.

Ако искате да забраните достъп до всички файлове и папки, използвайте &#8222;/&#8220;. Например

User-agent: *  
Disallow: /

ще забрани достъпа на който и да било робот до целия ви сайт.

User-agent: Googlebot-Image  
Disallow: /

пък ще забрани на робота за изображения на Google да индексира сайта ви.

Можете да разрешите достъпа само на един робот(в следния пример това е Googlebot) като първо му разрешите да обикаля всички страници, а след това забраните на всички роботи достъпа до сайта:

User-agent: Google  
Disallow:  
User-agent: *  
Disallow: /

Някои от по-главните роботи се съобразяват и с командата Allow, която разрешава индексирането на указания файл, намиращ се в иначе забранена директория. robots стандартът налага първата срещната за дадена папка команда и отминава всички следващи команди, отнасящи се до същата директория или до намиращи се в нея файлове. По тази причина за да използвате Allow за даден файл е необходимо командата да е записана преди Disallow командата за папката, в която се намира той. Например за да разрешите индексирането на файла index.php и едновременно да забраните индексирането на всички други файлове в неговата папка home трябва да напишете robots.txt така:

Allow: /home/index.php  
Disallow: /home/

Може ли robots.txt да ви предпази от лоши роботи?

Отговорът, за съжаление, е не. robots.txt има препоръчителен, а не задължителен характер и ако някой робот не желае да се съобразява с него, няма как да го накарате да го направи. Затова е препоръчително ако имате важни документи, които не искате да стават публични, да ги сложите в папки с ограничен достъп. За да посети някой &#8211; човек или робот, тези папки, ще трябва да въведе поставената от вас парола.

В заключение, създаването на файла robots.txt не е задължително и сайтът ви ще функционира и без него, но можете значително да оптимизирате работата на сайта си като намалите ненужен трафик.